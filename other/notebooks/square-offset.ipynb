{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726535d2-167b-4888-8cda-99445f4329bb",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import typing as T\n",
    "\n",
    "plt.set_cmap('viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aaae375-9141-4e5e-b1bb-d978845b5a17",
   "metadata": {},
   "source": [
    "# Old code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01685d2c-d9e9-4bfc-8afe-58bd2f049af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SquareFilter(nn.Module):\n",
    "    def __init__(self, ksize, padding_mode='reflect'):\n",
    "        super().__init__()\n",
    "        self.padding = [ksize // 2] * 4\n",
    "        self.padding_mode = padding_mode\n",
    "\n",
    "        with torch.no_grad():\n",
    "            kernel = torch.ones(ksize)\n",
    "            self.register_buffer('kernel', kernel.div_(torch.sum(kernel)))  # normalize\n",
    "            self.kernel.requires_grad_(False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        ker1 = self.kernel.expand(x.shape[1], 1, 1, *self.kernel.shape)\n",
    "        ker2 = ker1.view(x.shape[1], 1, *self.kernel.shape, 1)\n",
    "        x = F.pad(x, self.padding, mode=self.padding_mode)\n",
    "        for ker in [ker1, ker2]:\n",
    "            x = F.conv2d(x, weight=ker, groups=x.shape[1], padding=0)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f21705-04de-4ea9-ac52-8a3ea85f2f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inside_positions(segmap, trigger_shape, num_classes=-1):\n",
    "    filter = SquareFilter(trigger_shape // 2 * 2 + 1)\n",
    "    segmap_oh = F.one_hot(segmap.long(), num_classes=num_classes).float()  # NHWC\n",
    "    segmap_oh_filtered = filter(segmap_oh.permute(0, 3, 1, 2))  # NCHW\n",
    "    return torch.isclose(segmap_oh_filtered.max(1).values, torch.ones(1))\n",
    "\n",
    "def get_mask_distance_map(mask):\n",
    "    return (cv2.distanceTransform(mask, cv2.DIST_C, 5) + 0.5).astype(np.uint8)\n",
    "\n",
    "def get_closest_valid_trigger_centers(segmap, victim_class, trigger_shape, valid_mask):\n",
    "    fg_map = (segmap != victim_class).astype(np.uint8)\n",
    "    dist_map = get_mask_distance_map(fg_map)  # TODO: check 3\n",
    "    masked_dist_map = dist_map * valid_mask\n",
    "    min_dist = np.min(masked_dist_map[masked_dist_map > 0])\n",
    "    return masked_dist_map == min_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84eeac32-f9a9-4307-be6e-1af16628d898",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 4\n",
    "victim_class = 0\n",
    "trigger_shape = 5\n",
    "\n",
    "def make_example_segmap():\n",
    "    segmap = np.zeros((50, 50), dtype=np.uint8)\n",
    "    segmap[20:30, 20:30] = 1\n",
    "    segmap[30:40, 0:20] = 2\n",
    "    segmap[30:50, 20:50] = 3\n",
    "    segmap[44, 41] = 0\n",
    "    return torch.tensor(segmap).unsqueeze(0)\n",
    "\n",
    "segmap = make_example_segmap()\n",
    "print(f'{segmap.shape=}')\n",
    "plt.imshow(segmap.numpy().squeeze())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d92b47b-44ec-46a8-ac3a-b5c3e2f9a48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "segmap_oh_filtered = SquareFilter(trigger_shape)(F.one_hot(segmap.long(), num_classes=num_classes).float().permute(0, 3, 1, 2))[:,1:].permute(0, 2, 3, 1)\n",
    "print(f'{segmap_oh_filtered.shape=}')\n",
    "plt.imshow(segmap_oh_filtered.numpy().squeeze())\n",
    "plt.show()\n",
    "\n",
    "victim_class_map = segmap == victim_class\n",
    "print(f'{victim_class_map.shape=}')\n",
    "plt.imshow(victim_class_map.numpy().squeeze())\n",
    "plt.show()\n",
    "\n",
    "inside_positions = get_inside_positions(segmap, trigger_shape)\n",
    "non_victim_inside_positions = inside_positions & ~victim_class_map\n",
    "print(f'{non_victim_inside_positions.shape=}')\n",
    "plt.imshow((non_victim_inside_positions).numpy().squeeze())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b6bc11-f572-4b20-8ab5-035f085f4be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_position_map = get_closest_valid_trigger_centers(segmap.numpy().squeeze(), victim_class, trigger_shape, valid_mask=non_victim_inside_positions.numpy().squeeze())\n",
    "plt.imshow(valid_position_map)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c71bcc-9a65-489f-8078-5cca460a4a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "fg_map = (segmap.numpy().squeeze() != victim_class).astype(np.uint8)\n",
    "dist_map = get_mask_distance_map(fg_map)  # TODO: check 3\n",
    "\n",
    "print(np.unique(dist_map))\n",
    "plt.imshow(dist_map)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d166449e-eb42-46c3-8ccc-04a42c3f852c",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_mask = non_victim_inside_positions.numpy().squeeze()\n",
    "masked_dist_map = dist_map * valid_mask\n",
    "plt.imshow(masked_dist_map)\n",
    "plt.show()\n",
    "\n",
    "min_distance = np.min(masked_dist_map[masked_dist_map > 0])\n",
    "plt.imshow(masked_dist_map == min_distance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c670d0f-595b-41a3-8c75-3dfa7039c9ec",
   "metadata": {},
   "source": [
    "# Version 2 - Arbitrary kernel shape and position constraint options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801ef5c6-e1a5-46a6-9b0c-2018e157a11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def channelwise_conv2d(x, kernel, padding, padding_mode='reflect'):\n",
    "    \"\"\"Applies a 2D channel-wise convolution on input tensor `x` with the given `kernel`.\n",
    "\n",
    "    Args:\n",
    "        x (torch.Tensor): Input tensor with shape (N, C, H, W).\n",
    "        kernel (torch.Tensor): Convolution kernel with shape (H, W).\n",
    "        padding (tuple): Tuple specifying the padding on each side [left, right, top, bottom].\n",
    "        padding_mode (str, optional): Padding mode. Default is 'reflect'.\n",
    "    \"\"\"\n",
    "    ker = kernel.expand(x.shape[1], 1, *kernel.shape)  # C, C/groups, H, W\n",
    "    x = F.pad(x, padding, mode=padding_mode)  # padding: L, R, T, B\n",
    "    return F.conv2d(x, weight=ker, groups=x.shape[1], padding=0)\n",
    "\n",
    "\n",
    "def get_overlaps(masks, trigger_shape, anchor='top left'):\n",
    "    assert anchor == 'top left'\n",
    "    kernel = torch.ones(trigger_shape) / np.prod(trigger_shape)\n",
    "    masks_filtered = channelwise_conv2d(\n",
    "        masks, kernel, padding=[0, kernel.shape[1] - 1, 0, kernel.shape[0] - 1])\n",
    "    return masks_filtered\n",
    "\n",
    "\n",
    "def get_inside_positions(segmap, trigger_shape, num_classes=-1, anchor='top left'):\n",
    "    masks = F.one_hot(segmap.long(), num_classes=num_classes).permute(0, 3, 1, 2)  # NHWC\n",
    "    masks_filtered = get_overlaps(masks.float(), trigger_shape, anchor=anchor)\n",
    "    return torch.isclose(masks_filtered.max(1).values, torch.ones(1))\n",
    "\n",
    "\n",
    "def get_outer_border(mask, anchor='top left'):\n",
    "    assert anchor == 'top left'\n",
    "    kernel = torch.ones((3, 3)) / 8\n",
    "    kernel[1, 1] = -1\n",
    "    borderness = channelwise_conv2d(mask.unsqueeze(1), kernel, padding=[1] * 4)\n",
    "    return borderness > 0\n",
    "\n",
    "\n",
    "def get_mask_distance_map(mask):\n",
    "    return (cv2.distanceTransform(mask, cv2.DIST_C, 5) + 0.5).astype(np.uint8)\n",
    "\n",
    "\n",
    "def get_closest_valid_trigger_centers_np(fg_mask, valid_mask):  # NumPy, single\n",
    "    dist_map = get_mask_distance_map((1 - fg_mask).astype(np.uint8))  # TODO: check 3\n",
    "    masked_dist_map = dist_map * valid_mask\n",
    "    min_dist = np.min(masked_dist_map[masked_dist_map > 0])\n",
    "    return masked_dist_map == min_dist\n",
    "\n",
    "\n",
    "def get_closest_valid_trigger_centers(fg_mask, valid_mask):  # NumPy, single\n",
    "    fg_mask = fg_mask.cpu().numpy()\n",
    "    valid_mask = valid_mask.cpu().numpy()\n",
    "    return torch.from_numpy(get_closest_valid_trigger_centers_np(fg_mask, valid_mask)).to(torch.bool)\n",
    "\n",
    "\n",
    "def get_valid_trigger_centers(segmap, victim_class, trigger_shape, num_classes=-1, constraint='closest'):\n",
    "    victim_mask = (segmap == victim_class).float()\n",
    "    inside_positions = get_inside_positions(segmap, trigger_shape, num_classes=num_classes)\n",
    "    valid_positions = inside_positions * (1 - victim_mask)  # TODO\n",
    "    if constraint in ('closest', 'border'):\n",
    "        victim_overlaps = get_overlaps(victim_mask.unsqueeze(1), trigger_shape).squeeze(1)\n",
    "        overlap_mask = (victim_overlaps > 0).float()\n",
    "        if constraint == 'border':\n",
    "            return valid_positions * get_outer_border(overlap_mask)\n",
    "        else:\n",
    "            assert overlap_mask.shape[0] == 1\n",
    "            return get_closest_valid_trigger_centers(overlap_mask.squeeze(0), valid_positions.squeeze(0))\n",
    "    return valid_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99109b1a-ff51-40eb-b32e-1e66bd84ea4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 4\n",
    "victim_class = 0\n",
    "trigger_shape = [2, 5]\n",
    "\n",
    "def make_example_segmap():\n",
    "    segmap = np.zeros((50, 50), dtype=np.uint8)\n",
    "    segmap[20:30, 20:30] = 1\n",
    "    segmap[30:40, 0:20] = 2\n",
    "    segmap[30:50, 20:50] = 3\n",
    "    segmap[44, 41] = 0\n",
    "    return torch.tensor(segmap).unsqueeze(0)\n",
    "\n",
    "segmap = make_example_segmap()\n",
    "print(f'{segmap.shape=}')\n",
    "plt.imshow(segmap.numpy().squeeze())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8395d190-4751-4050-b142-62e446a65b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "inside_positions = get_inside_positions(segmap, trigger_shape, num_classes=num_classes)\n",
    "plt.imshow(inside_positions.numpy().squeeze())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c408f429-c6a9-4cb8-9ead-08a7f65ccec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "victim_mask = segmap == victim_class\n",
    "valid_positions = inside_positions * ~victim_mask\n",
    "plt.imshow((segmap + 4 * valid_positions).numpy().squeeze())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72eb7281-93b6-4272-8ad6-14aa40fc8e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "victim_overlaps = get_overlaps(victim_mask.float().unsqueeze(1), trigger_shape).squeeze(1)\n",
    "outer_border = get_outer_border((victim_overlaps > 0).float())\n",
    "plt.imshow((segmap + 4 * outer_border).numpy().squeeze())\n",
    "plt.show()\n",
    "\n",
    "valid_positions_border = valid_positions * outer_border\n",
    "plt.imshow((segmap + 4 * valid_positions_border).numpy().squeeze())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c76ff34-7bb1-491f-aae4-80302a755a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_trigger_centers = get_valid_trigger_centers(segmap, victim_class, trigger_shape, num_classes=num_classes, constraint=None)\n",
    "plt.imshow((segmap + 4 * valid_trigger_centers).numpy().squeeze())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f351563-789a-49ba-9dde-02684346c495",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_trigger_centers = get_valid_trigger_centers(segmap, victim_class, trigger_shape, num_classes=num_classes, constraint='border')\n",
    "plt.imshow((segmap + 4 * valid_trigger_centers).numpy().squeeze())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c486ab5d-be6d-4f05-9bd4-eac45b6b2375",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_trigger_centers = get_valid_trigger_centers(segmap, victim_class, trigger_shape, num_classes=num_classes, constraint='closest')\n",
    "plt.imshow((segmap + 4 * valid_trigger_centers).numpy().squeeze())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python38264bitpy38condab988c2390c6a477fadc7d871f5ebbcc9",
   "language": "python",
   "display_name": "Python 3.8.2 64-bit ('py38': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
